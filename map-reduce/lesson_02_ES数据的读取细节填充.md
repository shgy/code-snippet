es-hadoop默认的做法是使用perference参数读取指定的分片，来实现读取ES的并行化，我们延续这一思路。
但是基于业务特点做一个扩展。例如： 如果索引中有个枚举字段，那么查询使用分片+枚举字段， 就能组合成更多的查询了。 每个查询一个map任务，
那么并行化的程度更高了。
比如，如果我们熟悉业务表uuid的规则， 那么就可以使用前缀查询_id. 这个是很强大的并行化策略。
```
{"query":{ "prefix" : { "_id" : "A" }}}
```
这里还有一个问题： 就是读取数据的字段，从文本中读取，毫无疑问，都是字符串的，再做分割。 从ES或者其他数据库中读取，本来就各个类型的字段。




