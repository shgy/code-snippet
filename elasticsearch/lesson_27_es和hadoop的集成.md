在业务中，会有这样的需求。 快速将es的数据导出到redis或者kafka队列中，来满足业务交互的需求。比如将满足制定条件的
数据导出到redis中，进行运营活动，比如发券或者推送消息。这种操作，用户的量级一般在百万以上。如果这种操作不能扩展
到多机器，分布式处理。 一次的处理时间将特别漫长。个人觉得最好的流程应该是：
业务系统将需求提交到队列，任务调度从队列中取任务，集群操作，然后提供接口，由业务系统调用查看任务的状态。

业务系统  -----  任务处理系统(map-reduce/spark/storm/flink)

这个概念有点大，拆解一下。 如何使用map-reduce从es中导出数据？ 
map-reduce默认是处理hdfs文件。这里把数据源从文件换成了es, 当然也可以是其他的数据库。

接下来就是将ES的doc转化成Hadoop的Input，这里最简单的办法是JSON字符串。可以做到通用， 还有一种是JavaBean对象。












