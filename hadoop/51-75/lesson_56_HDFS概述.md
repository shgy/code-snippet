HDFS功能设计是围绕它的特性来的:

HDFS首要的功能就是容错.

"部件错误不再被当作异常,而是将其作为常见的情况加以处理".
在分布式环境下, 硬件的错误对系统而言不再是致命的. 所以Hadoop的容错机制非常重要.

对于DataNode, 使用心跳机制来容错.
对于NameNode, 使用HA, federation等机制容错.

不支持文件的随机写入.
   这个特性太棒了. 让我想到了"奥卡姆剃刀原则". 很多时侯, 我们都是希望具有什么特性, 而非拒绝什么特性.
大部分文件的更新是通过添加新数据完成的,而不是改变已存在的数据。  Lucene也是利用这个规则.

HDFS一共设计了3个角色: Master/Slave/Client

   只有一个master也极大的简化了设计并使得master可以根据全局情况作出先进的块放置和复制决定。但是我们必须要将
master对读和写的参与减至最少,这样它才不会成为系统的瓶颈。Client从来不会从master读和写文件数据。Client只是询
问master它应该和哪个 chunkserver(Slave)联系。Client在一段限定的时间内将这些信息缓存,在后续的操作中Client直接和
chunkserver(Slave)交互。
   当然这样做也导致了"单点故障".




