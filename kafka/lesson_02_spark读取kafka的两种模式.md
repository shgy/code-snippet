1. receiver-base模式
这种方式比较适合新手入门. 它使用了spark的高阶API, 操作比较简单. 实时把数据读取到内存. 由于生产和消费是异步, 
一旦消费不过来, 会在集群上产生大量的小文件, 影响hadoop的性能. 程序崩溃后, 也没有确定的offset, 容易丢数据.


2. direct模式
这种方式编程难度比较大, 需要自己控制的东西比较多. 按需取数据, 数据在kafka中, 需要多少取多少. 有点类似于懒操作的感觉.


这个得自己空了实践一把.


